---
title: "boat movement analysis"
author: "Tobias Schwoerer"
date: "November 21, 2018"
output: html_document
editor_options: 
  chunk_output_type: console
---

# Importing the data files, visualizing all respondent boat tracks 

```{r}
library(jsonlite)
library(geojson)
library(leaflet)
library(dplyr)
library(geojsonio)
library(tidyr)

#cleaned up features (tracks the respondents entered into the mapping tool)
#map <- geojson_read("D:/Dropbox/DATA/2018_boat_survey/map.geojson",what = "sp")
map <- geojson_read("C:/Users/Toby/Dropbox/DATA/2018_boat_survey/map.geojson", what = "sp")

#features <- read.csv("D:/Dropbox/DATA/2018_boat_survey/features.csv", stringsAsFactors = FALSE)
features <- read.csv("C:/Users/Toby/Dropbox/DATA/2018_boat_survey/features.csv", stringsAsFactors = FALSE)

#renaming misspelled column
names(features)[names(features)=="LenghtKM"] <- "km"


freqCoding <- read.csv("reference_tables/freqCoding.csv", stringsAsFactors = FALSE)

#cleaned data associated with the survey answers of each respondent
#data <- read.csv("D:/Dropbox/DATA/2018_boat_survey/data.csv", stringsAsFactors = FALSE)
data <- read.csv("C:/Users/Toby/Dropbox/DATA/2018_boat_survey/data.csv", stringsAsFactors = FALSE)

# the joined data and map output, joined these files using the python script
#mapdata <- geojson_read("D:/Dropbox/DATA/2018_boat_survey/output.geojson",what = "sp")
mapdata <- geojson_read("C:/Users/Toby/Dropbox/DATA/2018_boat_survey/output.geojson",what = "sp")

#creating leaflet map showing all routes
leaflet(mapdata) %>%
  addTiles() %>%
  addPolylines() %>%
  addProviderTiles(providers$Stamen.TerrainBackground)
```

#Calculating trip frequencies pre and post hypothetical elodea invasions of waterways used 
```{r}
#calculating pre elodea trip frequencies
features2 <- features%>%
  left_join(freqCoding,  by = c("trackFrequ"="Coding"))
features2$freqPre <- rowMeans(features2[c("Lower","Upper")], na.rm=TRUE)
#Renaming columns to specify fishing_region
names(features2)[names(features2)=="Lower"] <- "LowerPre"
names(features2)[names(features2)=="Upper"] <- "UpperPre"

#Calculating post elodea trip frequencies
features3 <- features2 %>%
  left_join(freqCoding,  by = c("trackFre_1"="Coding"))
features3$freqPost <- rowMeans(features3[c("Lower","Upper")], na.rm=TRUE)
#Renaming columns 
names(features3)[names(features3)=="Lower"] <- "LowerPost"
names(features3)[names(features3)=="Upper"] <- "UpperPost"
```

#Outliers and missing data for features
#Calculating annual cost of boating per route assumes average travel speed of 10 miles/h equal to 16km/h
```{r}
#calculating mean cost from the high and low cost per hour respondents reported
#last argument excludes missing values
features3$hCost <- rowMeans(features3[c("hCostHigh","hCostLow")], na.rm=TRUE)

#dealing with outlier on cost
features3$hCost[features3$hCost==20000] <- NA
hist(features3$hCost, breaks=20)

#dealing with outliers on km, setting frequency of trips pre if Up to 4 setting it to 1 if km >300
features3$freqPre <- with(features3, ifelse(km>300 & trackFrequ=="Up to 4",1,freqPre))

#dealing with ranks that are 0
features3$rank <- with(features3, ifelse(rank==0, 1, rank)) 

#dealing with missing values by first calculating the mediann cost per h then inserting missing values with the median
medianCost <- median(features3$hCost, na.rm=TRUE)
features3$hCost <- with(features3, ifelse(is.na(hCost), medianCost, hCost))

#calculating the total km per route then annual cost per route
features3$totalKmPre <- with(features3, km * freqPre)
features3$totalKmPost <- with(features3, km * freqPost)
features3$YrCostPre <- with(features3, totalKmPre * hCost)
features3$YrCostPost <- with(features3, totalKmPost * hCost)


#Creating descriptive stats tables
Hmisc::describe(features3$hCost )
Hmisc::describe(features3$YrCostPre)

tableData <- dplyr::select(features4, "hCost", "totalKm", "km", "freqPre", "freqPost", "primaryPur")
    
stargazer::stargazer(tableData, digits=0,  out="tables/table1.txt")
stargazer::stargazer(tableData, digits=0, type = "html", out="tables/table1.html")
```

In all of the above results the commercials are mixed in with the personal trips
# separating commercial from personal
```{r}
#getting rid of % sign in character string, then converting character to numeric, doing for percentCom and percentGov
data2 <- data
data2$percentCom <- gsub("[[:punct:]]", " ", data2$percentCom)
data2$percentCom <- as.numeric(as.character(data2$percentCom))
data2$percentCom <- with(data2, ifelse(is.na(percentCom),0,percentCom/100))
data2$percentGov <- gsub("[[:punct:]]", " ", data2$percentGov)
data2$percentGov <- as.numeric(as.character(data2$percentGov))
data2$percentGov <- with(data2, ifelse(is.na(percentGov),0,percentGov/100))
data2$percentPer <- with(data2, 1-percentGov-percentCom)

#turning character to numeric for income variable
incCoding <- read.csv("reference_tables/incCoding.csv", stringsAsFactors = FALSE)
data3 <- data2%>%
  dplyr::left_join(incCoding,  by = "persIncomeBtax")
data3$Income <- as.numeric(as.character(data3$Income))

#dealing with missing data on income
#dealing with missing values by first calculating the median income then inserting missing values with the median
medianIncome <- median(data3$Income, na.rm=TRUE)
data3$Income <- with(data3, ifelse(is.na(Income), medianIncome, Income))

#creating a selection of columns from data to join to features
resInfo <- dplyr::select(data3, responseID, percentPer, percentCom, percentGov, Income, freshOutside, CleanDrainDry, operateFresh, operateMarine)

features4 <- features3 %>%
 dplyr::left_join(resInfo, by = "responseID")
```

# exploring some data
```{r}


plot(features4$Income, features4$YrCostPre)
#has all types of operators mixed in

```



#Table showing main purpose of route by mean ranking
```{r}
StatsByPur <- features4 %>%
  dplyr::group_by(primaryPur)%>%
  summarise(percentRoutes = n()/nrow(features4),
            meanRank = mean(rank),
            count = n())%>%
  arrange(desc(count))
  
write.table(StatsByPur, file = "tables/table2.txt", sep = ",", quote = FALSE, row.names = F)

```


#High priority TASKS

2) can I visualize the frequencies on map? 
3) visualize out of state origin tracks

# Low priority tasks
3) Does a hex map make sense?
























# Integrating dynamic with static elements (Source: https://rstudio.github.io/leaflet/shiny.html)
```{r}
library(shiny)
library(leaflet)
library(RColorBrewer)

ui <- bootstrapPage(
  tags$style(type = "text/css", "html, body {width:100%;height:100%}"),
  leafletOutput("map", width = "100%", height = "100%"),
  absolutePanel(top = 10, right = 10,
    checkboxInput("select","Show tracks of",
      list(`boats operated outside Alaska before coming to Alaska` = list("NY", "NJ", "CT"),
           `boats Operated only in Alaska in 2018` = list(""),
           `all boats` = list("British Columbia","Washington","Kansas","Yukon Territories",""),
                selected = ""
           ),
      
        ),
    checkboxInput("legend", "Show legend", TRUE)
  )
)

```


```{r}
server <- function(input, output, session) {

  # Reactive expression for the data subsetted to what the user selected
  filteredData <- reactive({
    mapdata[mapdata$freshOutside =="Yes",]
  })

  # This reactive expression represents the palette function,
  # which changes as the user makes selections in UI.
  colorpal <- reactive({
    colorNumeric(input$colors, quakes$mag)
  })

  output$map <- renderLeaflet({
    # Use leaflet() here, and only include aspects of the map that
    # won't need to change dynamically (at least, not unless the
    # entire map is being torn down and recreated).
    leaflet(mapdata) %>% addTiles() %>%
      fitBounds(~min(long), ~min(lat), ~max(long), ~max(lat))
  })

  # Incremental changes to the map (in this case, replacing the
  # circles when a new color is chosen) should be performed in
  # an observer. Each independent set of things that can change
  # should be managed in its own observer.
  observe({
    pal <- colorpal()

    leafletProxy("map", data = filteredData()) %>%
      clearShapes() %>%
      addCircles(radius = ~10^mag/10, weight = 1, color = "#777777",
        fillColor = ~pal(mag), fillOpacity = 0.7, popup = ~paste(mag)
      )
  })

  # Use a separate observer to recreate the legend as needed.
  observe({
    proxy <- leafletProxy("map", data = quakes)

    # Remove any existing legend, and only if the legend is
    # enabled, create a new one.
    proxy %>% clearControls()
    if (input$legend) {
      pal <- colorpal()
      proxy %>% addLegend(position = "bottomright",
        pal = pal, values = ~mag
      )
    }
  })
}

shinyApp(ui, server)
 
``` 
 
```{r}
# write survey answers as geojson
geojson_write(answers, "data/answers.geojson")

#validating this file as a true json file
geojsonlint::geojson_lint("data/answers.geojson")

answersJson <- geojson_read("data/answers.geojson", what = "sp")

# combining json files
files <- c("routes", "answersJson")
jsonl <- lapply(files, function(f) fromJSON(file = f))
jsonc <- toJSON(jsonl)
write(jsonc, file = "jsonc")
class(jsonc)

#creating leaflet map
leaflet(data) %>%
  addTiles() %>%
  addPolylines() 
```

